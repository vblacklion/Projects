{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/B Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A/B testing is a way to compare two versions of a single variable, typically by testing a subject's response to variant A against variant B, and determining which of the two variants is more effective. It includes application of statistical hypothesis testing or \"two-sample hypothesis testing\" as used in the field of statistics.*(Wikipedia)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "The most successful companies today are the ones that know their customers so well that they can anticipate their needs. Customer analytics and in particular A/B Testing are crucial parts of leveraging quantitative know-how to help make business decisions that generate value. In this project I will cover the ins and outs of how to use Python to analyze customer behavior and business trends as well as how to create, run, and analyze A/B tests to make proactive, data-driven business decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading & Examining our data\n",
    "Let's begin by loading and examining two datasets: One that contains a set of user demographics and the other a set of data relating to in-app purchases for our meditation app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['uid', 'reg_date', 'device', 'gender', 'country', 'age'], dtype='object')\n",
      "Index(['date', 'uid', 'sku', 'price'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Import pandas \n",
    "import pandas as pd\n",
    "\n",
    "# Load the customer_data\n",
    "path = \"../../00_Common_Data_Sets/csv_files/ab_testing/\"\n",
    "customer_data = pd.read_csv(path+\"user_demographics_v1.csv\")\n",
    "\n",
    "# Load the app_purchases\n",
    "app_purchases = pd.read_csv(path+'purchase_data_v1.csv')\n",
    "\n",
    "# Print the columns of customer data\n",
    "print(customer_data.columns)\n",
    "\n",
    "# Print the columns of app_purchases\n",
    "print(app_purchases.columns)\n",
    "\n",
    "# Notice that both datasets have a common 'uid' column. We can use this columns to merge both!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging on different sets of fields\n",
    "As we saw both customer_data and app_purchases have a common 'uid' column that we can use to combine them. Also they have a common date column that is named 'date' in app_purchases and 'reg_date' in customer_data.\n",
    "\n",
    "Let's try merging on both of these columns and look at how this impacts our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date       uid            sku  price              reg_date device  \\\n",
      "0  2017-07-10  41195147  sku_three_499    499  2017-06-26T00:00:00Z    and   \n",
      "1  2017-07-15  41195147  sku_three_499    499  2017-06-26T00:00:00Z    and   \n",
      "2  2017-11-12  41195147   sku_four_599    599  2017-06-26T00:00:00Z    and   \n",
      "3  2017-09-26  91591874    sku_two_299    299  2017-01-05T00:00:00Z    and   \n",
      "4  2017-12-01  91591874   sku_four_599    599  2017-01-05T00:00:00Z    and   \n",
      "\n",
      "  gender country  age  \n",
      "0      M     BRA   17  \n",
      "1      M     BRA   17  \n",
      "2      M     BRA   17  \n",
      "3      M     TUR   17  \n",
      "4      M     TUR   17   \n",
      "\n",
      "The combined data has a lengt of 9006 rows as a result.\n"
     ]
    }
   ],
   "source": [
    "# Merge on the 'uid' field\n",
    "uid_combined_data = app_purchases.merge(customer_data, on=['uid'], how='inner')\n",
    "\n",
    "print(uid_combined_data.head(), \"\\n\")\n",
    "print(\"The combined data has a lengt of {} rows as a result.\".format(len(uid_combined_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to look at purchases that happened on the date of registration, we can merge customer_data to app_purchases on 'uid', 'date' and 'reg_date' columns. But we see that 'date' and 'reg_date' columns are in different formats. So we need to clean reg_date column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'date' column is of object data type and 'reg_date' is of object data type.\n"
     ]
    }
   ],
   "source": [
    "#First let's look at the data types of both date columns.\n",
    "print(\"'date' column is of {} data type and 'reg_date' is of {} data type.\".format(app_purchases.date.dtype,\n",
    "                                                                                   customer_data.reg_date.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>reg_date</th>\n",
       "      <th>device</th>\n",
       "      <th>gender</th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54030035.0</td>\n",
       "      <td>2017-06-29</td>\n",
       "      <td>and</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72574201.0</td>\n",
       "      <td>2018-03-05</td>\n",
       "      <td>iOS</td>\n",
       "      <td>F</td>\n",
       "      <td>TUR</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64187558.0</td>\n",
       "      <td>2016-02-07</td>\n",
       "      <td>iOS</td>\n",
       "      <td>M</td>\n",
       "      <td>USA</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92513925.0</td>\n",
       "      <td>2017-05-25</td>\n",
       "      <td>and</td>\n",
       "      <td>M</td>\n",
       "      <td>BRA</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99231338.0</td>\n",
       "      <td>2017-03-26</td>\n",
       "      <td>iOS</td>\n",
       "      <td>M</td>\n",
       "      <td>FRA</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          uid    reg_date device gender country  age\n",
       "0  54030035.0  2017-06-29    and      M     USA   19\n",
       "1  72574201.0  2018-03-05    iOS      F     TUR   22\n",
       "2  64187558.0  2016-02-07    iOS      M     USA   16\n",
       "3  92513925.0  2017-05-25    and      M     BRA   41\n",
       "4  99231338.0  2017-03-26    iOS      M     FRA   59"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# both of them are object data type. this means they are in string format. we need to convert them to date data type\n",
    "# but since the formats are the same we can simply slice the 'reg_date' column to extract only date part.\n",
    "\n",
    "customer_data.reg_date = customer_data.reg_date.str[:10]\n",
    "customer_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date       uid             sku  price    reg_date device gender  \\\n",
      "0  2016-03-30  94055095    sku_four_599    599  2016-03-30    iOS      F   \n",
      "1  2015-10-28  69627745     sku_one_199    199  2015-10-28    and      F   \n",
      "2  2017-02-02  11604973  sku_seven_1499    499  2017-02-02    and      F   \n",
      "3  2016-06-05  22495315    sku_four_599    599  2016-06-05    and      F   \n",
      "4  2018-02-17  51365662     sku_two_299    299  2018-02-17    iOS      M   \n",
      "\n",
      "  country  age  \n",
      "0     BRA   16  \n",
      "1     BRA   18  \n",
      "2     USA   16  \n",
      "3     USA   19  \n",
      "4     TUR   16   \n",
      "\n",
      "The combined data has a lengt of 35 rows as a result.\n"
     ]
    }
   ],
   "source": [
    "# Merge on the 'uid' and 'date' field\n",
    "uid_date_combined_data = app_purchases.merge(customer_data, left_on=['uid', 'date'], right_on=['uid', 'reg_date'],\n",
    "                                             how='inner')\n",
    "\n",
    "# Examine the results \n",
    "print(uid_date_combined_data.head(), \"\\n\")\n",
    "print(\"The combined data has a lengt of {} rows as a result.\".format(len(uid_date_combined_data)))\n",
    "\n",
    "# Note our second result returned fewer rows compared to the first one - 35 compared to 9006! \n",
    "# This is because there were fewer matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practicing aggregations\n",
    "\n",
    "Now we will begin exploring the in-app purchase data in more detail and practice aggregating the dataset in various ways using the .agg() method and then examine the results to get an understanding of the overall data, as well as a feel for how to aggregate data using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406.77259604707973 \n",
      "\n",
      "mean      406.772596\n",
      "median    299.000000\n",
      "Name: price, dtype: float64 \n",
      "\n",
      "             price        age\n",
      "mean    406.772596  23.922274\n",
      "median  299.000000  21.000000\n"
     ]
    }
   ],
   "source": [
    "purchase_data = uid_combined_data.copy()\n",
    "\n",
    "# Calculate the mean purchase price \n",
    "purchase_price_mean = purchase_data.price.agg('mean')\n",
    "print(purchase_price_mean, \"\\n\")\n",
    "\n",
    "# Calculate the mean and median purchase price \n",
    "purchase_price_summary = purchase_data.price.agg(['mean', 'median'])\n",
    "print(purchase_price_summary, \"\\n\")\n",
    "\n",
    "# Calculate the mean and median of price and age\n",
    "purchase_summary = purchase_data.agg({'price': ['mean', 'median'], 'age': ['mean', 'median']})\n",
    "print(purchase_summary)\n",
    "\n",
    "# Notice how the mean is higher than the median? This suggests that we have some users who are making a lot of purchases!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping & aggregating\n",
    "\n",
    "Now let's calculate a set of summary statistics about the purchase data broken out by 'device' (Android or iOS) and 'gender' (Male or Female).\n",
    "\n",
    "Following this, we'll compare the values across these subsets, which will give us a baseline for these values as potential KPIs to optimize going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>uid</th>\n",
       "      <th>sku</th>\n",
       "      <th>price</th>\n",
       "      <th>reg_date</th>\n",
       "      <th>device</th>\n",
       "      <th>gender</th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-07-10</td>\n",
       "      <td>41195147</td>\n",
       "      <td>sku_three_499</td>\n",
       "      <td>499</td>\n",
       "      <td>2017-06-26T00:00:00Z</td>\n",
       "      <td>and</td>\n",
       "      <td>M</td>\n",
       "      <td>BRA</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-07-15</td>\n",
       "      <td>41195147</td>\n",
       "      <td>sku_three_499</td>\n",
       "      <td>499</td>\n",
       "      <td>2017-06-26T00:00:00Z</td>\n",
       "      <td>and</td>\n",
       "      <td>M</td>\n",
       "      <td>BRA</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-11-12</td>\n",
       "      <td>41195147</td>\n",
       "      <td>sku_four_599</td>\n",
       "      <td>599</td>\n",
       "      <td>2017-06-26T00:00:00Z</td>\n",
       "      <td>and</td>\n",
       "      <td>M</td>\n",
       "      <td>BRA</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09-26</td>\n",
       "      <td>91591874</td>\n",
       "      <td>sku_two_299</td>\n",
       "      <td>299</td>\n",
       "      <td>2017-01-05T00:00:00Z</td>\n",
       "      <td>and</td>\n",
       "      <td>M</td>\n",
       "      <td>TUR</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>91591874</td>\n",
       "      <td>sku_four_599</td>\n",
       "      <td>599</td>\n",
       "      <td>2017-01-05T00:00:00Z</td>\n",
       "      <td>and</td>\n",
       "      <td>M</td>\n",
       "      <td>TUR</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       uid            sku  price              reg_date device  \\\n",
       "0  2017-07-10  41195147  sku_three_499    499  2017-06-26T00:00:00Z    and   \n",
       "1  2017-07-15  41195147  sku_three_499    499  2017-06-26T00:00:00Z    and   \n",
       "2  2017-11-12  41195147   sku_four_599    599  2017-06-26T00:00:00Z    and   \n",
       "3  2017-09-26  91591874    sku_two_299    299  2017-01-05T00:00:00Z    and   \n",
       "4  2017-12-01  91591874   sku_four_599    599  2017-01-05T00:00:00Z    and   \n",
       "\n",
       "  gender country  age  \n",
       "0      M     BRA   17  \n",
       "1      M     BRA   17  \n",
       "2      M     BRA   17  \n",
       "3      M     TUR   17  \n",
       "4      M     TUR   17  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchase_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    price                   \n",
      "                     mean median         std\n",
      "device gender                               \n",
      "and    F       400.747504    299  179.984378\n",
      "       M       416.237308    499  195.001520\n",
      "iOS    F       404.435330    299  181.524952\n",
      "       M       405.272401    299  196.843197\n"
     ]
    }
   ],
   "source": [
    "# Group the data \n",
    "grouped_purchase_data = purchase_data.groupby(by = ['device', 'gender'])\n",
    "\n",
    "# Aggregate the data\n",
    "purchase_summary = grouped_purchase_data.agg({'price': ['mean', 'median', 'std']})\n",
    "\n",
    "# Examine the results\n",
    "print(purchase_summary)\n",
    "\n",
    "# We see that the mean differs drastically from the median. Each male and female groups have some variabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating KPIs\n",
    "\n",
    "Now let's calculate the average amount paid per purchase within a user's first 28 days using the purchase_data DataFrame from before.\n",
    "\n",
    "This KPI can provide a sense of the popularity of different in-app purchase price points to users within their first month.\n",
    "\n",
    "Note: Prices in data are as of cents..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first import libraries\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date        object\n",
       "uid          int64\n",
       "sku         object\n",
       "price        int64\n",
       "reg_date    object\n",
       "device      object\n",
       "gender      object\n",
       "country     object\n",
       "age          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchase_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date columns to datetime\n",
    "purchase_data.date = pd.to_datetime(purchase_data.date).dt.date\n",
    "purchase_data.reg_date = pd.to_datetime(purchase_data.reg_date).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018-03-24'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_purchase_date.isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415.7741935483871\n"
     ]
    }
   ],
   "source": [
    "# current_date is the last day or max day in our data\n",
    "current_date = max(purchase_data.date)\n",
    "\n",
    "# Compute max_purchase_date\n",
    "max_purchase_date = current_date - timedelta(days=28)\n",
    "\n",
    "# Filter to only include users who registered before our max date\n",
    "purchase_data_filt = purchase_data[purchase_data.reg_date < max_purchase_date]\n",
    "\n",
    "# Filter to contain only purchases within the first 28 days of registration\n",
    "purchase_data_filt = purchase_data_filt[(purchase_data_filt.date <= \n",
    "                        purchase_data_filt.reg_date + timedelta(days=28))]\n",
    "\n",
    "# Output the mean price paid per purchase\n",
    "print(purchase_data_filt.price.mean())\n",
    "\n",
    "# Since our average price is 414 cents which is below $4.99 it seems that \n",
    "# our purchasers tend towards the lower priced set of options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring the average purchase price by cohort\n",
    "\n",
    "To deepen our understanding,  let's look at the same KPI, average purchase price, and a similar one, median purchase price, within the first 28 days. Additionally, let's look at these metrics not limited to 28 days to compare.\n",
    "\n",
    "We can calculate these metrics across a set of cohorts and see what differences emerge. This is a useful task as it can help us understand how behaviors vary across cohorts.\n",
    "\n",
    "Note that in our data the price variable is given in cents.\n",
    "\n",
    "Instructions 1/3\n",
    "\n",
    "Compute month1\n",
    "\n",
    "The price for purchases where:\n",
    "\n",
    "    (1) purchase_data.reg_date is less than max_reg_date\n",
    "\n",
    "    (2) purchase_data.date is less than purchase_data.reg_date plus 28 days and np.NaN for purchases that don't meet these conditions.\n",
    "\n",
    "Now, group purchase_data by gender then device using the .groupby() method.\n",
    "Aggregate the \"mean\" and \"median\" of 'month1' and'price' using the .agg() method in the listed order of aggregations and fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([499., 499.,  nan, ...,  nan,  nan,  nan])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where((purchase_data.reg_date < max_reg_date) &\n",
    "                 (purchase_data.date <= purchase_data.reg_date + timedelta(days=28)),\n",
    "                 purchase_data.price, np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  gender device      month1              price       \n",
      "                       mean median        mean median\n",
      "0      F    and  390.351351  299.0  400.747504    299\n",
      "1      F    iOS  432.333333  499.0  404.435330    299\n",
      "2      M    and  416.415730  499.0  416.237308    499\n",
      "3      M    iOS  435.206897  499.0  405.272401    299\n"
     ]
    }
   ],
   "source": [
    "# Set the max registration date to be one month before today\n",
    "max_reg_date = current_date - timedelta(days=28)\n",
    "\n",
    "# Find the month 1 values \n",
    "month1 = np.where((purchase_data.reg_date < max_reg_date) &\n",
    "                 (purchase_data.date <= purchase_data.reg_date + timedelta(days=28)),\n",
    "                 purchase_data.price, np.NaN)\n",
    "\n",
    "# Update the value in the DataFrame \n",
    "purchase_data['month1'] = month1\n",
    "\n",
    "# Group the data by gender and device \n",
    "purchase_data_upd = purchase_data.groupby(by=['gender', 'device'], as_index=False) \n",
    "\n",
    "# Aggregate the month1 and price data \n",
    "purchase_summary = purchase_data_upd.agg(\n",
    "                        {'month1': ['mean', 'median'],\n",
    "                        'price': ['mean', 'median']})\n",
    "\n",
    "# Examine the results \n",
    "print(purchase_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring and Visualizing Customer Behavior\n",
    "Now we will try to visualize, manipulate, and explore KPIs as they change over time. Through a variety of examples, you'll learn how to work with datetime objects to calculate metrics per unit time. Then we move to the techniques for how to graph different segments of data, and apply various smoothing functions to reveal hidden trends. Finally we walk through a complete example of how to pinpoint issues through exploratory data analysis of customer data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing dates\n",
    "\n",
    "Now we will practice parsing dates in Python. Knowing how to properly parse dates is crucial to get the data in a workable format. For reference refer to http://strftime.org/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the correct format for the date\n",
    "date_data_one = pd.to_datetime(date_data_one, format='%A %B %d, %Y')\n",
    "print(date_data_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions 2/4\n",
    "25 XP\n",
    "Provide the correct format for the following date:\n",
    "\n",
    "2017-08-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the correct format for the date\n",
    "date_data_two = pd.to_datetime(date_data_two, format='%Y-%m-%d')\n",
    "print(date_data_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions 3/4\n",
    "25 XP\n",
    "Provide the correct format for the following date.\n",
    "\n",
    "08/17/1978"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the correct format for the date\n",
    "date_data_three = pd.to_datetime(date_data_three, format='%m/%d/%Y')\n",
    "print(date_data_three)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions 4/4\n",
    "25 XP\n",
    "Provide the correct format for the following date:\n",
    "\n",
    "2016 March 01 01:56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the correct format for the date\n",
    "date_data_four = pd.to_datetime(date_data_four, format='%Y %B %d %H:%M')\n",
    "print(date_data_four)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting time series data\n",
    "In trying to boost purchases, we have made some changes to our introductory in-app purchase pricing. In this exercise, you will check if this is having an impact on the number of purchases made by purchasing users during their first week.\n",
    "\n",
    "The dataset user_purchases has been joined to the demographics data and properly filtered. The column 'first_week_purchases' that is 1 for a first week purchase and 0 otherwise has been added. This column is converted to the average number of purchases made per day by users in their first week.\n",
    "\n",
    "We will try to view the impact of this change by looking at a graph of purchases as described in the instructions.\n",
    "\n",
    "Instructions\n",
    "100 XP\n",
    "Instructions\n",
    "100 XP\n",
    "Read through and understand code shown and then plot the user_purchases data with 'reg_date' on the x-axis and 'first_week_purchases' on the y-axis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data and aggregate first_week_purchases\n",
    "user_purchases = user_purchases.groupby(by=['reg_date', 'uid']).agg({'first_week_purchases': ['sum']})\n",
    "\n",
    "# Reset the indexes\n",
    "user_purchases.columns = user_purchases.columns.droplevel(level=1)\n",
    "user_purchases.reset_index(inplace=True)\n",
    "\n",
    "# Find the average number of purchases per day by first-week users\n",
    "user_purchases = user_purchases.groupby(by=['reg_date']).agg({'first_week_purchases': ['mean']})\n",
    "user_purchases.columns = user_purchases.columns.droplevel(level=1)\n",
    "user_purchases.reset_index(inplace=True)\n",
    "\n",
    "# Plot the results\n",
    "user_purchases.plot(x='reg_date', y='first_week_purchases')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivoting our data\n",
    "As you saw, there does seem to be an increase in the number of purchases by purchasing users within their first week. Let's now confirm that this is not driven only by one segment of users. We'll do this by first pivoting our data by 'country' and then by 'device'. Our change is designed to impact all of these groups equally.\n",
    "\n",
    "The user_purchases data from before has been grouped and aggregated by the 'country' and 'device' columns. These objects are available in your workspace as user_purchases_country and user_purchases_device.\n",
    "\n",
    "As a reminder, .pivot_table() has the following signature:\n",
    "\n",
    "pd.pivot_table(data, values, columns, index)\n",
    "Instructions 1/2\n",
    "50 XP\n",
    "1\n",
    "Pivot the user_purchases_country table such that we have our first_week_purchases as our values, the country as the column, and our reg_date as the row.\n",
    "\n",
    "Take Hint (-15 XP)\n",
    "2\n",
    "Now lets look at our device data. Let us pivot the user_purchases_device table such that we have our first_week_purchases as our values, the device as the column, and our reg_date as the row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the data\n",
    "country_pivot = pd.pivot_table(user_purchases_country, values=['first_week_purchases'], \n",
    "                               columns=['country'], index=['reg_date'])\n",
    "print(country_pivot.head())\n",
    "\n",
    "# Pivot the data\n",
    "device_pivot = pd.pivot_table(user_purchases_device, values=['first_week_purchases'], \n",
    "                              columns=['device'], index=['reg_date'])\n",
    "print(device_pivot.head())\n",
    "\n",
    "# Having the data in this form is not very conducive to examining trends on its own. \n",
    "# Next we will plot the data which should illuminate anything interesting in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xamining the different cohorts\n",
    "To finish this lesson, you're now going to plot by 'country' and then by 'device' and examine the results. Hopefully you will see the observed lift across all groups as designed. This would point to the change being the cause of the lift, not some other event impacting the purchase rate.\n",
    "\n",
    "Instructions 1/2\n",
    "50 XP\n",
    "Instructions 1/2\n",
    "50 XP\n",
    "1\n",
    "Plot the average first week purchases for each country by registration date ('reg_date'). There are 6 countries here: 'USA', 'CAN', 'FRA', 'BRA', 'TUR', and 'DEU'. Plot them in the order shown.\n",
    "\n",
    "Take Hint (-15 XP)\n",
    "2\n",
    "Now, plot the average first week purchases for each device ('and' and 'iOS') by registration date ('reg_date'). Plot the devices in the order listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the average first week purchases for each country by registration date\n",
    "country_pivot.plot(x='reg_date', y=['USA', 'CAN', 'FRA', 'BRA', 'TUR', 'DEU'])\n",
    "plt.show()\n",
    "\n",
    "# Plot the average first week purchases for each device by registration date\n",
    "device_pivot.plot(x='reg_date', y=['and', 'iOS'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seasonality and moving averages\n",
    "Stepping back, we will now look at the overall revenue data for our meditation app. We saw strong purchase growth in one of our products, and now we want to see if that is leading to a corresponding rise in revenue. As you may expect, revenue is very seasonal, so we want to correct for that and unlock macro trends.\n",
    "\n",
    "In this exercise, we will correct for weekly, monthly, and yearly seasonality and plot these over our raw data. This can reveal trends in a very powerful way.\n",
    "\n",
    "The revenue data is loaded for you as daily_revenue.\n",
    "\n",
    "Instructions\n",
    "100 XP\n",
    "Instructions\n",
    "100 XP\n",
    "Using the .rolling() method, find the rolling average of the data with a 7 day window and store it in a column 7_day_rev.\n",
    "Find the monthly (28 days) rolling average and store it in a column 28_day_rev.\n",
    "Find the yearly (365 days) rolling average and store it in a column 365_day_rev.\n",
    "Hit 'Submit Answer' to plot the three calculated rolling averages together along with the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute 7_day_rev\n",
    "daily_revenue['7_day_rev'] = daily_revenue.revenue.rolling(window=7, center=False).mean()\n",
    "\n",
    "# Compute 28_day_rev\n",
    "daily_revenue['28_day_rev'] = daily_revenue.revenue.rolling(window=28, center=False).mean()\n",
    "    \n",
    "# Compute 365_day_rev\n",
    "daily_revenue['365_day_rev'] = daily_revenue.revenue.rolling(window=365, center=False).mean()\n",
    "    \n",
    "# Plot date, and revenue, along with the 3 rolling functions (in order)    \n",
    "daily_revenue.plot(x='date', y=['revenue', '7_day_rev', '28_day_rev', '365_day_rev', ])\n",
    "plt.show()\n",
    "\n",
    "# Notice that while there is a lot of seasonality, our revenue seems to be somewhat flat over this time period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exponential rolling average & over/under smoothing\n",
    "In the previous exercise, we saw that our revenue is somewhat flat over time. In this exercise we will dive deeper into the data to see if we can determine why this is the case. We will look at the revenue for a single in-app purchase product we are selling to see if this potentially reveals any trends. As this will have less data then looking at our overall revenue it will be much noisier. To account for this we will smooth the data using an exponential rolling average.\n",
    "\n",
    "A new daily_revenue dataset has been provided for us, containing the revenue for this product.\n",
    "\n",
    "Instructions\n",
    "100 XP\n",
    "Using the .ewm() method, calculate the exponential rolling average with a span of 10 and store it in a column small_scale.\n",
    "Repeat the previous step, now with a span of 100 and store it in a column medium_scale.\n",
    "Finally, calculate the exponential rolling average with a span of 500 and store it in a column large_scale.\n",
    "Plot the three averages, along with the raw data. Examine how clear the trend of the data is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate 'small_scale'\n",
    "daily_revenue['small_scale'] = daily_revenue.revenue.ewm(span=10).mean()\n",
    "\n",
    "# Calculate 'medium_scale'\n",
    "daily_revenue['medium_scale'] = daily_revenue.revenue.ewm(span=100).mean()\n",
    "\n",
    "# Calculate 'large_scale'\n",
    "daily_revenue['large_scale'] = daily_revenue.revenue.ewm(span=500).mean()\n",
    "\n",
    "# Plot 'date' on the x-axis and, our three averages and 'revenue'\n",
    "# on the y-axis\n",
    "daily_revenue.plot(x = 'date', y =['revenue', 'small_scale', 'medium_scale', 'large_scale'])\n",
    "plt.show()\n",
    "\n",
    "#  Note that the medium window strikes the right balance. \n",
    "# Revenue seems to be growing in this product so it must not be the cause of the overall flat revenue trend!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing user spending\n",
    "Recently, the Product team made some big changes to both the Android & iOS apps. They do not have any direct concerns about the impact of these changes, but want you to monitor the data to make sure that the changes don't hurt company revenue. Additionally, the product team believes that some of these changes may impact female users more than male users.\n",
    "\n",
    "In this exercise you're going to plot the monthly revenue for one of the updated products and evaluate the results.\n",
    "\n",
    "The dataset user_revenue containing the 'device', 'gender', 'country', 'date', and 'revenue' has been loaded. It has been grouped by month, device, and gender. Note that here, a 'month' column has been extracted from the 'date' column.\n",
    "\n",
    "Instructions\n",
    "100 XP\n",
    "Instructions\n",
    "100 XP\n",
    "Pivot user_revenue such that we have the 'month' as the rows (index),'device' and 'gender' as our columns and 'revenue' as our values.\n",
    "Remove the first and last row of the DataFrame once pivoted to prevent discontinuities from distorting the results. This has been done for you.\n",
    "Plot pivoted_data using its .plot() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot user_revenue\n",
    "pivoted_data = pd.pivot_table(user_revenue, values ='revenue', columns=['device', 'gender'], index='month')\n",
    "pivoted_data = pivoted_data[1:(len(pivoted_data) -1 )]\n",
    "\n",
    "# Create and show the plot\n",
    "pivoted_data.plot()\n",
    "plt.show()\n",
    "\n",
    "# From this view, it seems like our aggregate revenue is fairly stable, so the changes are most likely not hurting revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A/B test generalizability\n",
    "Listed below are a set of decisions that could be made when designing an A/B test. Identify the decision that would not cause an issue in generalizing the test results to the overall user population.\n",
    "\n",
    "Answer the question\n",
    "50 XP\n",
    "Possible Answers\n",
    "Assigning users to the Test or Variant group based on their signup year.\n",
    "press\n",
    "1\n",
    "Using a hash of the randomly assigned user id to determine user groupings. (CORRECT ANSWER - This is a fine thing to do and a common way to tie the group a user belongs to to their identity.)\n",
    "press\n",
    "2\n",
    "Randomly assigning users within one country to different groups.\n",
    "press\n",
    "3\n",
    "Allowing users to change groups every time they use the service or software.\n",
    "press\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
