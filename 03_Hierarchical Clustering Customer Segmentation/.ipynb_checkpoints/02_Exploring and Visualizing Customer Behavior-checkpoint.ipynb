{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring and Visualizing Customer Behavior\n",
    "0%\n",
    "This chapter teaches you how to visualize, manipulate, and explore KPIs as they change over time. Through a variety of examples, you'll learn how to work with datetime objects to calculate metrics per unit time. Then we move to the techniques for how to graph different segments of data, and apply various smoothing functions to reveal hidden trends. Finally we walk through a complete example of how to pinpoint issues through exploratory data analysis of customer data. Throughout this chapter various functions are introduced and explained in a highly generalizable way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing dates\n",
    "In this exercise you will practice parsing dates in Python. While often data pulled from a database will be correctly formatted, other data sources can be less nice. Knowing how to properly parse dates is crucial to get the data in a workable format. For reference refer to http://strftime.org/ throughout this exercise to see date format to use.\n",
    "\n",
    "Instructions 1/4\n",
    "\n",
    "Provide the correct format for the following date:\n",
    "\n",
    "Saturday January 27, 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the correct format for the date\n",
    "date_data_one = pd.to_datetime(date_data_one, format='%A %B %d, %Y')\n",
    "print(date_data_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions 2/4\n",
    "25 XP\n",
    "Provide the correct format for the following date:\n",
    "\n",
    "2017-08-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the correct format for the date\n",
    "date_data_two = pd.to_datetime(date_data_two, format='%Y-%m-%d')\n",
    "print(date_data_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions 3/4\n",
    "25 XP\n",
    "Provide the correct format for the following date.\n",
    "\n",
    "08/17/1978"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the correct format for the date\n",
    "date_data_three = pd.to_datetime(date_data_three, format='%m/%d/%Y')\n",
    "print(date_data_three)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions 4/4\n",
    "25 XP\n",
    "Provide the correct format for the following date:\n",
    "\n",
    "2016 March 01 01:56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the correct format for the date\n",
    "date_data_four = pd.to_datetime(date_data_four, format='%Y %B %d %H:%M')\n",
    "print(date_data_four)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting time series data\n",
    "In trying to boost purchases, we have made some changes to our introductory in-app purchase pricing. In this exercise, you will check if this is having an impact on the number of purchases made by purchasing users during their first week.\n",
    "\n",
    "The dataset user_purchases has been joined to the demographics data and properly filtered. The column 'first_week_purchases' that is 1 for a first week purchase and 0 otherwise has been added. This column is converted to the average number of purchases made per day by users in their first week.\n",
    "\n",
    "We will try to view the impact of this change by looking at a graph of purchases as described in the instructions.\n",
    "\n",
    "Instructions\n",
    "100 XP\n",
    "Instructions\n",
    "100 XP\n",
    "Read through and understand code shown and then plot the user_purchases data with 'reg_date' on the x-axis and 'first_week_purchases' on the y-axis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data and aggregate first_week_purchases\n",
    "user_purchases = user_purchases.groupby(by=['reg_date', 'uid']).agg({'first_week_purchases': ['sum']})\n",
    "\n",
    "# Reset the indexes\n",
    "user_purchases.columns = user_purchases.columns.droplevel(level=1)\n",
    "user_purchases.reset_index(inplace=True)\n",
    "\n",
    "# Find the average number of purchases per day by first-week users\n",
    "user_purchases = user_purchases.groupby(by=['reg_date']).agg({'first_week_purchases': ['mean']})\n",
    "user_purchases.columns = user_purchases.columns.droplevel(level=1)\n",
    "user_purchases.reset_index(inplace=True)\n",
    "\n",
    "# Plot the results\n",
    "user_purchases.plot(x='reg_date', y='first_week_purchases')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivoting our data\n",
    "As you saw, there does seem to be an increase in the number of purchases by purchasing users within their first week. Let's now confirm that this is not driven only by one segment of users. We'll do this by first pivoting our data by 'country' and then by 'device'. Our change is designed to impact all of these groups equally.\n",
    "\n",
    "The user_purchases data from before has been grouped and aggregated by the 'country' and 'device' columns. These objects are available in your workspace as user_purchases_country and user_purchases_device.\n",
    "\n",
    "As a reminder, .pivot_table() has the following signature:\n",
    "\n",
    "pd.pivot_table(data, values, columns, index)\n",
    "Instructions 1/2\n",
    "50 XP\n",
    "1\n",
    "Pivot the user_purchases_country table such that we have our first_week_purchases as our values, the country as the column, and our reg_date as the row.\n",
    "\n",
    "Take Hint (-15 XP)\n",
    "2\n",
    "Now lets look at our device data. Let us pivot the user_purchases_device table such that we have our first_week_purchases as our values, the device as the column, and our reg_date as the row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the data\n",
    "country_pivot = pd.pivot_table(user_purchases_country, values=['first_week_purchases'], \n",
    "                               columns=['country'], index=['reg_date'])\n",
    "print(country_pivot.head())\n",
    "\n",
    "# Pivot the data\n",
    "device_pivot = pd.pivot_table(user_purchases_device, values=['first_week_purchases'], \n",
    "                              columns=['device'], index=['reg_date'])\n",
    "print(device_pivot.head())\n",
    "\n",
    "# Having the data in this form is not very conducive to examining trends on its own. \n",
    "# Next we will plot the data which should illuminate anything interesting in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xamining the different cohorts\n",
    "To finish this lesson, you're now going to plot by 'country' and then by 'device' and examine the results. Hopefully you will see the observed lift across all groups as designed. This would point to the change being the cause of the lift, not some other event impacting the purchase rate.\n",
    "\n",
    "Instructions 1/2\n",
    "50 XP\n",
    "Instructions 1/2\n",
    "50 XP\n",
    "1\n",
    "Plot the average first week purchases for each country by registration date ('reg_date'). There are 6 countries here: 'USA', 'CAN', 'FRA', 'BRA', 'TUR', and 'DEU'. Plot them in the order shown.\n",
    "\n",
    "Take Hint (-15 XP)\n",
    "2\n",
    "Now, plot the average first week purchases for each device ('and' and 'iOS') by registration date ('reg_date'). Plot the devices in the order listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the average first week purchases for each country by registration date\n",
    "country_pivot.plot(x='reg_date', y=['USA', 'CAN', 'FRA', 'BRA', 'TUR', 'DEU'])\n",
    "plt.show()\n",
    "\n",
    "# Plot the average first week purchases for each device by registration date\n",
    "device_pivot.plot(x='reg_date', y=['and', 'iOS'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seasonality and moving averages\n",
    "Stepping back, we will now look at the overall revenue data for our meditation app. We saw strong purchase growth in one of our products, and now we want to see if that is leading to a corresponding rise in revenue. As you may expect, revenue is very seasonal, so we want to correct for that and unlock macro trends.\n",
    "\n",
    "In this exercise, we will correct for weekly, monthly, and yearly seasonality and plot these over our raw data. This can reveal trends in a very powerful way.\n",
    "\n",
    "The revenue data is loaded for you as daily_revenue.\n",
    "\n",
    "Instructions\n",
    "100 XP\n",
    "Instructions\n",
    "100 XP\n",
    "Using the .rolling() method, find the rolling average of the data with a 7 day window and store it in a column 7_day_rev.\n",
    "Find the monthly (28 days) rolling average and store it in a column 28_day_rev.\n",
    "Find the yearly (365 days) rolling average and store it in a column 365_day_rev.\n",
    "Hit 'Submit Answer' to plot the three calculated rolling averages together along with the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute 7_day_rev\n",
    "daily_revenue['7_day_rev'] = daily_revenue.revenue.rolling(window=7, center=False).mean()\n",
    "\n",
    "# Compute 28_day_rev\n",
    "daily_revenue['28_day_rev'] = daily_revenue.revenue.rolling(window=28, center=False).mean()\n",
    "    \n",
    "# Compute 365_day_rev\n",
    "daily_revenue['365_day_rev'] = daily_revenue.revenue.rolling(window=365, center=False).mean()\n",
    "    \n",
    "# Plot date, and revenue, along with the 3 rolling functions (in order)    \n",
    "daily_revenue.plot(x='date', y=['revenue', '7_day_rev', '28_day_rev', '365_day_rev', ])\n",
    "plt.show()\n",
    "\n",
    "# Notice that while there is a lot of seasonality, our revenue seems to be somewhat flat over this time period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exponential rolling average & over/under smoothing\n",
    "In the previous exercise, we saw that our revenue is somewhat flat over time. In this exercise we will dive deeper into the data to see if we can determine why this is the case. We will look at the revenue for a single in-app purchase product we are selling to see if this potentially reveals any trends. As this will have less data then looking at our overall revenue it will be much noisier. To account for this we will smooth the data using an exponential rolling average.\n",
    "\n",
    "A new daily_revenue dataset has been provided for us, containing the revenue for this product.\n",
    "\n",
    "Instructions\n",
    "100 XP\n",
    "Using the .ewm() method, calculate the exponential rolling average with a span of 10 and store it in a column small_scale.\n",
    "Repeat the previous step, now with a span of 100 and store it in a column medium_scale.\n",
    "Finally, calculate the exponential rolling average with a span of 500 and store it in a column large_scale.\n",
    "Plot the three averages, along with the raw data. Examine how clear the trend of the data is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate 'small_scale'\n",
    "daily_revenue['small_scale'] = daily_revenue.revenue.ewm(span=10).mean()\n",
    "\n",
    "# Calculate 'medium_scale'\n",
    "daily_revenue['medium_scale'] = daily_revenue.revenue.ewm(span=100).mean()\n",
    "\n",
    "# Calculate 'large_scale'\n",
    "daily_revenue['large_scale'] = daily_revenue.revenue.ewm(span=500).mean()\n",
    "\n",
    "# Plot 'date' on the x-axis and, our three averages and 'revenue'\n",
    "# on the y-axis\n",
    "daily_revenue.plot(x = 'date', y =['revenue', 'small_scale', 'medium_scale', 'large_scale'])\n",
    "plt.show()\n",
    "\n",
    "#  Note that the medium window strikes the right balance. \n",
    "# Revenue seems to be growing in this product so it must not be the cause of the overall flat revenue trend!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing user spending\n",
    "Recently, the Product team made some big changes to both the Android & iOS apps. They do not have any direct concerns about the impact of these changes, but want you to monitor the data to make sure that the changes don't hurt company revenue. Additionally, the product team believes that some of these changes may impact female users more than male users.\n",
    "\n",
    "In this exercise you're going to plot the monthly revenue for one of the updated products and evaluate the results.\n",
    "\n",
    "The dataset user_revenue containing the 'device', 'gender', 'country', 'date', and 'revenue' has been loaded. It has been grouped by month, device, and gender. Note that here, a 'month' column has been extracted from the 'date' column.\n",
    "\n",
    "Instructions\n",
    "100 XP\n",
    "Instructions\n",
    "100 XP\n",
    "Pivot user_revenue such that we have the 'month' as the rows (index),'device' and 'gender' as our columns and 'revenue' as our values.\n",
    "Remove the first and last row of the DataFrame once pivoted to prevent discontinuities from distorting the results. This has been done for you.\n",
    "Plot pivoted_data using its .plot() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot user_revenue\n",
    "pivoted_data = pd.pivot_table(user_revenue, values ='revenue', columns=['device', 'gender'], index='month')\n",
    "pivoted_data = pivoted_data[1:(len(pivoted_data) -1 )]\n",
    "\n",
    "# Create and show the plot\n",
    "pivoted_data.plot()\n",
    "plt.show()\n",
    "\n",
    "# From this view, it seems like our aggregate revenue is fairly stable, so the changes are most likely not hurting revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A/B test generalizability\n",
    "Listed below are a set of decisions that could be made when designing an A/B test. Identify the decision that would not cause an issue in generalizing the test results to the overall user population.\n",
    "\n",
    "Answer the question\n",
    "50 XP\n",
    "Possible Answers\n",
    "Assigning users to the Test or Variant group based on their signup year.\n",
    "press\n",
    "1\n",
    "Using a hash of the randomly assigned user id to determine user groupings. (CORRECT ANSWER - This is a fine thing to do and a common way to tie the group a user belongs to to their identity.)\n",
    "press\n",
    "2\n",
    "Randomly assigning users within one country to different groups.\n",
    "press\n",
    "3\n",
    "Allowing users to change groups every time they use the service or software.\n",
    "press\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
